{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "touched-integration",
   "metadata": {},
   "source": [
    "## Face Recognition ##\n",
    "\n",
    "To do Face Recognition I can't use a preexisting model as the ones use in `dlib` or `opencv` and I'll have to do something a little more manual. But before doing that, let me get a source of photos. The best one, right now, is Instagram and here's how I'll be getting photos from public accounts.\n",
    "\n",
    "### 01. Lambdas & Iterators ###\n",
    "\n",
    "First, I'll need to install [instaloader](https://instaloader.github.io/) which is a Python module that allows me to download recent pots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "going-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install instaloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-killer",
   "metadata": {},
   "source": [
    "Next, let me show you how to use instaloader. I'll take advantage of this to explain a little bit about iterators and lambda functions.\n",
    "\n",
    "Let me start with the simple thing: lambda functions. So, a lambda function is actually a function without a name, that always returns something. The syntax is this one:\n",
    "\n",
    "`lambda x : some_operation_with(x)` - remember, in this example I used `x` as a random name; you can have one or more arguments and you can really be creative with their names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "composite-region",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this:\n",
    "f = lambda a : a + 2\n",
    "print('f(2):', f(2), 'f is', type(f))\n",
    "# is actually equivalent to this:\n",
    "def f(a):\n",
    "    return a + 2\n",
    "print('f(2):', f(2), 'f is', type(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-climb",
   "metadata": {},
   "source": [
    "Then why use it? After all this is just a restricted way to define a function. Well, because it's nice to be lazy, like in this example where I'll compute a list of squares of the first 10 numbers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-machine",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this:\n",
    "l = list(map(lambda x : x**2, range(10)))\n",
    "print(l)\n",
    "# vs this:\n",
    "def square(x): return x**2\n",
    "l = []\n",
    "for n in range(10): l.append(square(n))\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-appreciation",
   "metadata": {},
   "source": [
    "Also, there's a speed advantage for the first method when compared with the second for very large lists. But I'm pretty sure you noticed something: that I've wrapped the `map` function in a `list` cast (*cast* - the transformation of one data type to another). This is because `map` returns an `iterator`. So what is an `iterator`? That's pretty simple:\n",
    "\n",
    "An iterator is returning the current value with the promise than next time it will be called, I'll get the next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adjusted-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = map(lambda x : x**2, range(10))\n",
    "print('type of it:', type(it))\n",
    "print('1st call:', next(it))\n",
    "print('2nd call:', next(it))\n",
    "print('3rd call:', next(it))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driving-trainer",
   "metadata": {},
   "source": [
    "So why use it? Well, to save memory! This way, you don't need to know all the elements of a set, but just the rule that builds that set. So here's how you can create an iterator (actually, this is really called a *generator*, a particular *iterator* case, that is really simple to construct):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "civic-privacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares(n):\n",
    "    \"\"\"\n",
    "    This function will return an iterator for all the squared integers less than n^2.\n",
    "    @param n (int) : will return all the squared integers until n^2\n",
    "    @return int : an iterator for all squared integers less than n^2.\n",
    "    \"\"\"\n",
    "    i = 0 # start with a value\n",
    "    while i < n:\n",
    "        yield i**2\n",
    "        i += 1\n",
    "\n",
    "list(squares(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descending-oxygen",
   "metadata": {},
   "source": [
    "And I also can write something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-hamburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sq in squares(10):\n",
    "    print(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imperial-melissa",
   "metadata": {},
   "source": [
    "The good thing about the above approach is that at any point only one value will be stored in the memory. Iterators are mostly used in list comprehension (creating list from other lists, like in a for loop, like this):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-strain",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ x + 2 for x in squares(10) ] # computes the list of numbers x^2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "severe-uncle",
   "metadata": {},
   "source": [
    "One last thing about this: if I'd like to extract only parts of the iterator (for example squares from 3^2 until 10^2), I can use `dropwhile` and `takewhile` from the standard library module `itertools`.\n",
    "- `dropwhile(lambda, element)` will discard all the values from the iterator until the first moment the lambda applied to the element will become False; so, if the lambda is False from the beginning, nothing will be discaded; also, if the lambda will return True for some elements after it previously returned False, those values are not discarded;\n",
    "- `takewhile(lambda, element)` works exactly like `dropwhile` but will keep the element instead of discarding it; same rules apply for the lambda;\n",
    "\n",
    "And yes, of course, instead of lambda you can use any other kind of function, normal or method ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-officer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import dropwhile, takewhile\n",
    "# Get the squares after 9:\n",
    "print([ x for x in dropwhile(lambda sq : sq <= 9 , squares(10)) ])\n",
    "# Get the squares before 16:\n",
    "print([ x for x in takewhile(lambda sq : sq < 16, squares(10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consistent-sharing",
   "metadata": {},
   "source": [
    "### 02. Getting Images from Instagram ###\n",
    "\n",
    "Putting things together now, here's how I'll be using instaloader:\n",
    "- first, I'll instantiate the `Instaloader` object from `instaloader` module; this will allow me to interact with Instagram;\n",
    "- I'm going to get an iterator to all the post by first building a `Profile` profile from the Instagram ID and will call the `get_posts()` method which creates an iterator;\n",
    "- I'll use `dropwhile` and `takewhile` to filter the post for a given interval;\n",
    "- and put the results in a list;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-simpson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from itertools import dropwhile, takewhile\n",
    "\n",
    "import instaloader\n",
    "\n",
    "profile_id = 'valerie.lungu' # please, add here the instagram profile\n",
    "\n",
    "# this is me, instantiating the Instaloader object\n",
    "L = instaloader.Instaloader()\n",
    "# building the profile\n",
    "profile = instaloader.Profile.from_username(L.context, profile_id)\n",
    "# and retrieve an iterator to the posts\n",
    "posts = profile.get_posts()\n",
    "\n",
    "# these are the limits for the posts\n",
    "since = datetime(2021, 3, 1)\n",
    "until = datetime(2021, 4, 6)\n",
    "\n",
    "# construct an empty list for the urls\n",
    "image_urls = []\n",
    "\n",
    "# do the dropwhile and takewhile trick:\n",
    "for post in dropwhile(lambda post: post.date > until, takewhile(lambda post: post.date > since, posts)):\n",
    "    # and if this post is an image\n",
    "    if not post.is_video:\n",
    "        # add the image url to the list\n",
    "        image_urls.append(post.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comfortable-despite",
   "metadata": {},
   "source": [
    "The results from running the cell above produces a list of image URLs that I can verify in the browser:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "casual-foster",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-study",
   "metadata": {},
   "source": [
    "So if I have the URL, I need to manually download the picture to use it? No, of course not. I can use the builtin `urllib` which allows me to open webpages using the `request.urlopen(url)` method. I convert the response (which is a `byte` string) to array and decode it so I'll obtain a normal matrix. I've put everything in the following short function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-apollo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import urllib\n",
    "import numpy as np\n",
    "\n",
    "def image_from_url(url):\n",
    "    \"\"\"\n",
    "    Read an image from an URL and returns the image matrix.\n",
    "    @param url (string) : the URL for the image;\n",
    "    @return (numpy.array) : a matrix containing the image information.\n",
    "    \"\"\"\n",
    "    response = urllib.request.urlopen(url)\n",
    "    image_enc = np.asarray(bytearray(response.read()), dtype=np.uint8)\n",
    "    image = cv2.imdecode(image_enc, cv2.IMREAD_COLOR)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-barrier",
   "metadata": {},
   "source": [
    "Now I'll test the image download function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image = image_from_url(image_urls[1])\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "plt.imshow(image[:,:,::-1]) # this trick switches the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-innocent",
   "metadata": {},
   "source": [
    "### 03. Siameze Networks ###\n",
    "\n",
    "I don't know if you realized what is actually a Machine Learning algorithm? Well, from the mathematical point of view is just a matrix function that takes a real-valued matrix as input and produces a real-value matrix as output.\n",
    "\n",
    "$$Y = f_{ML}(X)$$\n",
    "\n",
    "The sizes of both matrices need not match. Actually, in practice, this never happens. The learning part happens like this $f_{ML}$ has actually one internal state that changes while training and which when predicting is used in computing the output value.\n",
    "\n",
    "Now to my problem: to be able to tell if two faces are the same, I have two options:\n",
    "- either create this kind of *function* that takes as input two images and produces as output a single number (which is also a matrix, but with only one row and one column);\n",
    "- or create a transformation *function* from an image to another structure, so that when this transformation is applied on both images, you can measure the distance between their outputs;\n",
    "\n",
    "While the first method is possible, it's applications are few as it might be more complex to make it general. While the second one, just allows you to learn a very general transformation that from a face will extract *features*. This second method is called a **Siameze Network** as both images that will be compared are passed through the same **network**. This is a deep learning method as usually there's a large number of layers involved.\n",
    "\n",
    "So, how to make a siameze network? Actually, this being a very known and useful problem, there are plenty of siameze networks already done and better, pretrained - so no other work is need for it. The one I'll be using is called [FaceNet](https://github.com/davidsandberg/facenet). To download the pretrained FaceNet model execute the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-thompson",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/uc?id=1PZ_6Zsy1Vb0s0JmjEmVd8FS99zoMCiN1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "respected-efficiency",
   "metadata": {},
   "source": [
    "Next, to load this model I've just downloaded, I need [tensorflow](https://www.tensorflow.org/) which is Google's helper library for building and playing with Machine Learning methods.\n",
    "\n",
    "After importing it, I'll disable all the INFO and WARNING messages, to keep things cleaner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-glenn",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "available-sierra",
   "metadata": {},
   "source": [
    "But tensorflow is a low level library. It requires you to define all the dependencies and operations inside and between the layers. So Google came to resque and created keras, which is a high level library wrapper for tensorflow - meaning the nasty things are hidden inside and you can call very few things to make it work. Keras comes with a load_model function that I'll use and which can import a saved model like the one I've just downloaded. The returned object exposes a method named `predict()` that can be applied on a matrix and generate the output of $f_ML$.\n",
    "\n",
    "To know exactly what the model requires as input and what it will produce as output, I can use the `inputs` and `outputs` properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-emphasis",
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "theoretical-break",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load the model\n",
    "model = load_model('facenet_keras.h5')\n",
    "# summarize input and output shape\n",
    "print('inputs:', model.inputs)\n",
    "print('outputs:', model.outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hairy-ultimate",
   "metadata": {},
   "source": [
    "So cool! So this method requires a matrix of 160x160x3 (so square image, of 160x160 with 3 channels and they are in RGB format - this is something I know reading the documentation, not from seeing the input) and produces as output a vector with 128 components.\n",
    "\n",
    "But is it taking long to run? I can use `time.time()` from the builtin `time` module to count the number of microseconds while the prediction runs on a matrix full of zeros. You'll also notice that the matrix I used for input is of size 1x160x160x3 - this is because you can apply the model on a lot of images at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-insert",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\\\n",
    "\n",
    "input_shape = tuple(model.inputs[0].shape[1:])\n",
    "\n",
    "prediction_start = time.time()\n",
    "prediction = model.predict(np.zeros((1,) + input_shape))\n",
    "prediction_time = time.time() - prediction_start\n",
    "\n",
    "prediction_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "different-zoning",
   "metadata": {},
   "source": [
    "### 04. Prepare Faces ###\n",
    "\n",
    "But FaceNet is just for faces - not for generic images containing faces. So I need a method to extract and prepare the faces from a given image. From the previous notebook, I'll use the `dlib.get_frontal_face_detector` object that is specifically designed for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seasonal-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "def detect_faces(frame):\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray)\n",
    "    return faces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advance-roommate",
   "metadata": {},
   "source": [
    "The bad part is that I can't use this as input directly, as while this is a square face, it doesn't have the exact size required. So I'll need a little preparation before. I'll put the preparation in a function that will produce the matrix needed for the model input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instrumental-holder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_faces(frame):\n",
    "    \"\"\"\n",
    "    This function will extract the faces from a frame and will create a matrix from them,\n",
    "    that can be fed through the FaceNet model. The function uses dlib to extract the\n",
    "    rectangles, after that it will cut the faces, resize them and concatenate them in a\n",
    "    matrix. To not lose the bounding boxes (rectangles surrounding the faces), I'll add\n",
    "    those also to a second matrix.\n",
    "    @param frame (numpy.array) : the image frame where I'll search for faces;\n",
    "    @return tuple(numpy.array, numpy.array) : the first element will be a matrix that\n",
    "    can be fed through the FaceNet model, while the second one is a matrix that has on\n",
    "    each row the top, left, bottom, right coordinates of the bounding rectangle.\n",
    "    \"\"\"\n",
    "    # this will be the output matrices\n",
    "    faces = None # the model input matrix\n",
    "    boxes = None # the bounding boxes matrix\n",
    "    \n",
    "    # go through all the detected faces\n",
    "    for box in detect_faces(frame):\n",
    "        # extract the face from the image\n",
    "        face = frame[box.top():box.bottom(), box.left():box.right(), :]\n",
    "        # resize the face to match the required size\n",
    "        face = cv2.resize(face, input_shape[:2])\n",
    "        # add the first axis, to be able to concatenate the outputs\n",
    "        face = face.reshape(1, *input_shape)\n",
    "        # if this is the first face, just put it in the output\n",
    "        if faces is None:\n",
    "            faces = face\n",
    "            boxes = np.array([[\n",
    "                box.top(),\n",
    "                box.left(),\n",
    "                box.bottom(),\n",
    "                box.right()\n",
    "            ]])\n",
    "        # if this is not the first face, i'll concatenate it\n",
    "        else:\n",
    "            faces = np.concatenate((faces, face), axis = 0)\n",
    "            boxes = np.concatenate((boxes, np.array([[\n",
    "                box.top(),\n",
    "                box.left(),\n",
    "                box.bottom(),\n",
    "                box.right()\n",
    "            ]])), axis = 0)\n",
    "    \n",
    "    return faces, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "breeding-thompson",
   "metadata": {},
   "source": [
    "Running the face extraction and preparation on the first image from the list, gives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-demographic",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces, boxes = prepare_faces(image)\n",
    "for face in faces:\n",
    "    plt.imshow(face[:,:,::-1])\n",
    "faces.shape, boxes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beneficial-reception",
   "metadata": {},
   "source": [
    "### 05. Face Signatures ###\n",
    "\n",
    "Now that I can extract faces from a random input image and prepare them for the correct machine learning algorithm input, let's see how the image gets converted: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deluxe-harvest",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize = (10, 2), gridspec_kw={'width_ratios': [1, 4]}) # create a 1-row, 2-column plot, with 1:4 column ratio\n",
    "\n",
    "signature = model.predict(faces)\n",
    "ax[0].imshow(faces[0][:,:,::-1])\n",
    "ax[1].plot(signature[0])\n",
    "signature.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "golden-fortune",
   "metadata": {},
   "source": [
    "As this works for one of the faces, the next step is to generalize for all the selected posts from the profile I chose. The next cell will go through all the images, get the faces and their signatures and storedthem in `face_signatues` and `face_images` lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "turkish-arabic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define two lists to hold the data\n",
    "face_signatures = [] # one for signatures\n",
    "face_images = [] # one for face images\n",
    "\n",
    "# go through all the urls I've got from Instagram\n",
    "for image_url in image_urls:\n",
    "    # download and extract the image matrix\n",
    "    image = image_from_url(image_url)\n",
    "    # convert it to RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    # extract the prepared faces\n",
    "    faces, boxes = prepare_faces(image)\n",
    "    if faces is None:\n",
    "        continue\n",
    "    # and get the signatures\n",
    "    signatures = model.predict(faces)\n",
    "    # put the faces in their list\n",
    "    for face_index, face in enumerate(faces):\n",
    "        face_images.append(face)\n",
    "        face_signatures.append(signatures[face_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unique-board",
   "metadata": {},
   "source": [
    "The next cell will show how the signature graphs compare to eachother. You can notice that the signatures are pretty similar, given the faces are from the same person. This is how face recognition works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(len(face_images), 2, gridspec_kw={'width_ratios': [1, 4]})\n",
    "for face_index, face in enumerate(face_images):\n",
    "    ax[face_index, 0].imshow(face)\n",
    "    ax[face_index, 1].plot(face_signatures[face_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-israeli",
   "metadata": {},
   "source": [
    "### 06. Cosine Distance ###\n",
    "\n",
    "Looks good! Now, there are a lot of distances that I can use between two vectors - cause this is the output of the model, a 128-component vector. For similarity, the best that I can use is the cosine-distance which will tell me the cosine of the angle between those two vectors. Unlike anyother norms, this is a distance that encodes the differences between the vector components, iregardless of each component amplitude. This is based on this formula:\n",
    "$$ \\langle h_1, h_2 \\rangle = |h_1||h_2|cos(\\sphericalangle(h_1, h_2)) $$\n",
    "\n",
    "Which leads to this formula:\n",
    "\n",
    "$$d_{cos}(h_1, h_2) = \\frac{\\langle h_1, h_2 \\rangle}{|h_1||h_2|}$$\n",
    "\n",
    "For which I've implemented this function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "double-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_distance(signature_A, signature_B):\n",
    "    \"\"\"\n",
    "    Returns the cosine distance between vectors signature_A and signature_B.\n",
    "    @param signature_A (np.array) : the first vector;\n",
    "    @param signature_B (np.array) : the second vector;\n",
    "    @return (float) : a number, representing the cosine distance.\n",
    "    \"\"\"\n",
    "    return np.matmul(signature_A, signature_B) / (np.linalg.norm(signature_A) * np.linalg.norm(signature_B))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entitled-blogger",
   "metadata": {},
   "source": [
    "Now, I'll compute the cosine distance between every face. Actually, as this distance is commutative and it will be 1.00 for the same image, all I have to do is to loop through the faces and compare each faces with the ones with strictly higher index.\n",
    "\n",
    "I'll put the results into a matrix - but using this method I described, the matrix will be strictly upper-triangular so I'll need to add the identity matrix to it (one's on the diagonal) and it's transpose (a strictly lower-triangular matrix), to get the full picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_no = len(face_signatures)\n",
    "# prepare the resulting matrix\n",
    "results = np.zeros((faces_no, faces_no))\n",
    "# for each face\n",
    "for i in range(faces_no):\n",
    "    # get each face with a higher index\n",
    "    for j in range(i + 1, faces_no):\n",
    "        # and compute the distance\n",
    "        results[i,j] = cos_distance(face_signatures[i], face_signatures[j])\n",
    "# build a matrix that is symmetric and has 1.00 on the main diagonal\n",
    "results = results + np.eye(faces_no) + results.transpose()\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-cartoon",
   "metadata": {},
   "source": [
    "Or better, I can use `matshow` from `matplotlib.pyplot` to draw a nice image of the matrix: the lighter colors represent a bigger match, while the dark colors represent a lower match between the compared faces:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "packed-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-better",
   "metadata": {},
   "source": [
    "In order to see the percentages better, I can loop for each cell coordinates and put the text containing the percentage in that cell, using `matplotlib.pyplot.text`, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-torture",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(results)\n",
    "\n",
    "for i in range(faces_no):\n",
    "    for j in range(faces_no):\n",
    "        plt.text(i, j, '%d%%' % int(100 * results[i,j]), va='center', ha='center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moving-headset",
   "metadata": {},
   "source": [
    "Or the more advanced, where I draw each faces on top of the axis, to see which faces look more to the others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-dominant",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to use subplots for this, this means than in a single image I'll have a matrix of (1, 1) subplots.\n",
    "# The rest is actually the code to display the matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.matshow(results)\n",
    "# Together with getting the plot position on the canvas\n",
    "pos = ax.get_position()\n",
    "\n",
    "# Put also the percentages on the canvas, as I did before\n",
    "for i in range(faces_no):\n",
    "    for j in range(faces_no):\n",
    "        ax.text(i, j, '%d%%' % int(100 * results[i,j]), va='center', ha='center')\n",
    "\n",
    "# Compute the width and height of the matrix plot (the information, not the axis)\n",
    "w = pos.x1 - pos.x0 # this is the width of the plot\n",
    "h = pos.y1 - pos.y0 # this is the height of the plot\n",
    "# Compute the width and height of a single cell:\n",
    "img_w = w / faces_no # this is the width of one cell\n",
    "img_h = h / faces_no # this is the height of one cell\n",
    "\n",
    "# I'm using enumerate which provides not only the object but also an index for it\n",
    "for num, image in enumerate(face_images):\n",
    "    # I'm adding a new subplot, on the position starting from x0 (left) and on y1 (top) of the plot\n",
    "    ax_w = fig.add_axes([pos.x0 + num * img_w, pos.y1, img_w, img_h])\n",
    "    # I'll not display the number axis\n",
    "    ax_w.axison = False\n",
    "    # but will show the image\n",
    "    ax_w.imshow(image)\n",
    "    # Also, add a new subplot, on the position starting one cell left of x0 and going down from y1 (top)\n",
    "    ax_h = fig.add_axes([pos.x0 - img_w, pos.y1 - (num + 1) * img_h, img_w, img_h])\n",
    "    # same tricks, no number axis\n",
    "    ax_h.axison = False\n",
    "    # and display the image\n",
    "    ax_h.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-prairie",
   "metadata": {},
   "source": [
    "So if I want to consider a few pictures to have a reference on how the instagram model looks like, I can do the following trick:\n",
    "- take the average of the cosine distance for each image when compared to the others;\n",
    "- take the standard deviation of the cosine distance for on each image when compare to the others;\n",
    "\n",
    "By computing the $ \\mu - 5\\sigma $ we get the minimum estimated distance threshold for a face when compared to others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spare-frame",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.bar(range(results.shape[0]), np.mean(results, axis = 1) - 5 * np.std(results, axis = 1))\n",
    "pos = ax.get_position()\n",
    "\n",
    "margins = ax.margins()\n",
    "# Compute the width and height of the matrix plot (the information, not the axis)\n",
    "w = pos.x1 - pos.x0 - margins[0] # this is the width of the plot\n",
    "h = pos.y1 - pos.y0 - margins[1]# this is the height of the plot\n",
    "# Compute the width and height of a single cell:\n",
    "img_w = w / faces_no # this is the width of one cell\n",
    "img_h = h / faces_no # this is the height of one cell\n",
    "\n",
    "# I'm using enumerate which provides not only the object but also an index for it\n",
    "for num, image in enumerate(face_images):\n",
    "    # I'm adding a new subplot, on the position starting from x0 (left) and on y1 (top) of the plot\n",
    "    ax_w = fig.add_axes([pos.x0 + margins[0] * 0.5 + num * img_w, img_h + margins[1] * 0.5, img_w, img_h])\n",
    "    # I'll not display the number axis\n",
    "    ax_w.axison = False\n",
    "    # but will show the image\n",
    "    ax_w.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-trade",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-tf2",
   "language": "python",
   "name": "python-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
